{
  "question_id" : 44806125,
  "title" : "AttributeError: &#39;Model&#39; object has no attribute &#39;predict_classes&#39;",
  "body" : "<p>I'm trying to predict on the validation data with pre-trained and fine-tuned DL models. The code follows the example available in the Keras blog on \"building image classification models using very little data\". Kindly do not mind the number of samples used in training and validation. Here is the code:</p>\n\n<pre><code>import numpy as np\nfrom keras.preprocessing.image import ImageDataGenerator\nimport matplotlib.pyplot as plt\nfrom keras.models import Sequential\nfrom keras.models import Model\nfrom keras.layers import Flatten, Dense\nfrom sklearn.metrics import classification_report,confusion_matrix\nfrom sklearn.metrics import roc_auc_score\nimport itertools\nfrom keras.optimizers import SGD\nfrom sklearn.metrics import roc_curve, auc\nfrom keras import applications\nfrom keras import backend as K\nK.set_image_dim_ordering('tf')\n\n# Plotting the confusion matrix\ndef plot_confusion_matrix(cm, classes,\n                          normalize=False, #if true all values in confusion matrix is between 0 and 1\n                          title='Confusion matrix',\n                          cmap=plt.cm.Blues):\n    \"\"\"\n    This function prints and plots the confusion matrix.\n    Normalization can be applied by setting `normalize=True`.\n    \"\"\"\n    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n    plt.title(title)\n    plt.colorbar()\n    tick_marks = np.arange(len(classes))\n    plt.xticks(tick_marks, classes, rotation=45)\n    plt.yticks(tick_marks, classes)\n\n    if normalize:\n        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n        print(\"Normalized confusion matrix\")\n    else:\n        print('Confusion matrix, without normalization')\n\n    print(cm)\n    thresh = cm.max() / 2.\n    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n        plt.text(j, i, cm[i, j],\n                 horizontalalignment=\"center\",\n                 color=\"white\" if cm[i, j] &gt; thresh else \"black\")\n    plt.tight_layout()\n    plt.ylabel('True label')\n    plt.xlabel('Predicted label')\n\n#plot data\ndef generate_results(validation_labels, y_pred):\n    fpr, tpr, _ = roc_curve(validation_labels, y_pred) ##(this implementation is restricted to a binary classification task)\n    roc_auc = auc(fpr, tpr)\n    plt.figure()\n    plt.plot(fpr, tpr, label='ROC curve (area = %0.2f)' % roc_auc)\n    plt.plot([0, 1], [0, 1], 'k--')\n    plt.xlim([0.0, 1.05])\n    plt.ylim([0.0, 1.05])\n    plt.xlabel('False Positive Rate (FPR)')\n    plt.ylabel('True Positive Rate (TPR)')\n    plt.title('Receiver operating characteristic (ROC) curve')\n    plt.show()\n    print('Area Under the Curve (AUC): %f' % roc_auc)\n\nimg_width, img_height = 100,100\ntop_model_weights_path = 'modela.h5'\ntrain_data_dir = 'data4/train'\nvalidation_data_dir = 'data4/validation'\nnb_train_samples = 20\nnb_validation_samples = 20\nepochs = 50\nbatch_size = 10\ndef save_bottleneck_features():\n   datagen = ImageDataGenerator(rescale=1. / 255)\n   model = applications.VGG16(include_top=False, weights='imagenet', input_shape=(100,100,3))\n   generator = datagen.flow_from_directory(\n               train_data_dir,\n               target_size=(img_width, img_height),\n               batch_size=batch_size,\n               class_mode='binary',\n               shuffle=False)\n   bottleneck_features_train = model.predict_generator(\n               generator, nb_train_samples // batch_size)\n   np.save(open('bottleneck_features_train', 'wb'),bottleneck_features_train)\n\n   generator = datagen.flow_from_directory(\n               validation_data_dir,\n               target_size=(img_width, img_height),\n               batch_size=batch_size,\n               class_mode='binary',\n               shuffle=False)\n   bottleneck_features_validation = model.predict_generator(\n               generator, nb_validation_samples // batch_size)\n   np.save(open('bottleneck_features_validation', 'wb'),bottleneck_features_validation)\n\ndef train_top_model():\n   train_data = np.load(open('bottleneck_features_train', 'rb'))\n   train_labels = np.array([0] * (nb_train_samples // 2) + [1] * (nb_train_samples // 2))\n   validation_data = np.load(open('bottleneck_features_validation', 'rb'))\n   validation_labels = np.array([0] * (nb_validation_samples // 2) + [1] * (nb_validation_samples // 2))\n   model = Sequential()\n   model.add(Flatten(input_shape=train_data.shape[1:]))\n   model.add(Dense(512, activation='relu'))\n   model.add(Dense(1, activation='sigmoid'))\n   sgd = SGD(lr=1e-3, decay=0.00, momentum=0.99, nesterov=False) \n   model.compile(optimizer=sgd,\n         loss='binary_crossentropy', metrics=['accuracy'])\n   model.fit(train_data, train_labels,\n          epochs=epochs,\n          batch_size=batch_size,\n   validation_data=(validation_data, validation_labels))\n   model.save_weights(top_model_weights_path)\n   print('Predicting on test data')\n   y_pred = model.predict_classes(validation_data)\n   print(y_pred.shape)\n   print('Generating results')\n   generate_results(validation_labels[:,], y_pred[:,])\n   print('Generating the ROC_AUC_Scores') #Compute Area Under the Curve (AUC) from prediction scores\n   print(roc_auc_score(validation_labels,y_pred)) #this implementation is restricted to the binary classification task or multilabel classification task in label indicator format.\n   target_names = ['class 0(Normal)', 'class 1(Abnormal)']\n   print(classification_report(validation_labels,y_pred,target_names=target_names))\n   print(confusion_matrix(validation_labels,y_pred))\n   cnf_matrix = (confusion_matrix(validation_labels,y_pred))\n   np.set_printoptions(precision=2)\n   plt.figure()\n   # Plot non-normalized confusion matrix\n   plot_confusion_matrix(cnf_matrix, classes=target_names,\n                      title='Confusion matrix')\n   plt.show()\nsave_bottleneck_features()\ntrain_top_model()\n\n# path to the model weights files.\nweights_path = '../keras/examples/vgg16_weights.h5'\ntop_model_weights_path = 'modela.h5'\n# dimensions of our images.\nimg_width, img_height = 100, 100\ntrain_data_dir = 'data4/train'\nvalidation_data_dir = 'data4/validation'\nnb_train_samples = 20\nnb_validation_samples = 20\nepochs = 50\nbatch_size = 10\n\n# build the VGG16 network\nbase_model = applications.VGG16(weights='imagenet', include_top=False, input_shape=(100,100,3))\nprint('Model loaded.')\n\ntrain_datagen = ImageDataGenerator(\n    rescale=1. / 255,\n    shear_range=0.2,\n    zoom_range=0.2,\n    horizontal_flip=True)\ntest_datagen = ImageDataGenerator(rescale=1. / 255)\ntrain_generator = train_datagen.flow_from_directory(\n    train_data_dir,\n    target_size=(img_height, img_width),\n    batch_size=batch_size,\n    class_mode='binary')\nvalidation_generator = test_datagen.flow_from_directory(\n    validation_data_dir,\n    target_size=(img_height, img_width),\n    batch_size=batch_size,\n    class_mode='binary') \ntop_model = Sequential()\ntop_model.add(Flatten(input_shape=base_model.output_shape[1:]))\ntop_model.add(Dense(512, activation='relu'))\ntop_model.add(Dense(1, activation='softmax'))\ntop_model.load_weights(top_model_weights_path)\nmodel = Model(inputs=base_model.input, outputs=top_model(base_model.output))\n   # set the first 15 layers (up to the last conv block)\n# to non-trainable (weights will not be updated)\nfor layer in model.layers[:15]: #up to the layer before the last convolution block\n        layer.trainable = False\nmodel.summary()\n   # fine-tune the model\nmodel.compile(loss='binary_crossentropy', optimizer=SGD(lr=1e-4, momentum=0.99), metrics=['accuracy'])\nmodel.fit_generator(train_generator,\n    steps_per_epoch=nb_train_samples // batch_size,\n    epochs=epochs,\n    validation_data=validation_generator,\n    validation_steps=nb_validation_samples // batch_size,\n    verbose=1)\nmodel.save_weights(top_model_weights_path)\nbottleneck_features_validation = model.predict_generator(validation_generator, nb_validation_samples // batch_size)\nnp.save(open('bottleneck_features_validation','wb'), bottleneck_features_validation)\nvalidation_data = np.load(open('bottleneck_features_validation', 'rb'))\ny_pred1 = model.predict_classes(validation_data)\n</code></pre>\n\n<p>The problem is that the pre-trained model is getting trained on the data and predicts the classes perfectly and gives the confusion matrix as well. As I proceed to fine-tuning the model, I could find that model.predict_classes is not working. Here is the error:</p>\n\n<pre><code>File \"C:/Users/rajaramans2/codes/untitled12.py\", line 220, in &lt;module&gt;\n    y_pred1 = model.predict_classes(validation_data)\n\nAttributeError: 'Model' object has no attribute 'predict_classes'\n</code></pre>\n\n<p>I'm puzzled by this error because model.predict_classes worked well with the pre-trained model but not in the fine-tuning stage. The size of validation data is (20,1) and float32 type. Would be great if you can help resolve this. Thanks in advance. </p>\n",
  "link" : "https://stackoverflow.com/questions/44806125/attributeerror-model-object-has-no-attribute-predict-classes",
  "owner" : {
    "user_id" : 7575552,
    "user_type" : "registered",
    "display_name" : "shiva",
    "profile_image" : "https://www.gravatar.com/avatar/aa97cb0a77feacae03226a98555f56e8?s=128&d=identicon&r=PG&f=1",
    "link" : "https://stackoverflow.com/users/7575552/shiva",
    "reputation" : 7,
    "accept_rate" : 60
  },
  "is_answered" : false,
  "creation_date" : 1498661944,
  "last_activity_date" : 1498661944,
  "tags" : [
    "compiler-errors",
    "keras",
    "prediction"
  ],
  "score" : 0,
  "view_count" : 2,
  "answer_count" : 0
}